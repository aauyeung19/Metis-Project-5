{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Doc2Vec Notebook\n",
    "Author: Andrew Auyeung  \n",
    "\n",
    "References: [Detecting Document Similarity with doc2vec](https://towardsdatascience.com/detecting-document-similarity-with-doc2vec-f8289a9a7db7)\n",
    "\n",
    "Versions:  \n",
    "doc2vec_v1 - FSM.  \n",
    "doc2vec_v2 - retrained with doctags as an entire element. \n",
    "doc2vec_v3 - remove \"TDS Editors\" from authors.  Their articles were mainly links to other articles and did not have any text to their body.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "model = Doc2Vec.load('../models/d2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load articles\n",
    "articles = pd.read_csv('../src/TDS_articles.csv', sep='\\t', index_col=0)"
   ]
  },
  {
   "source": [
    "Lets check that the word2vec model works.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('quality', 0.3656102120876312),\n",
       " ('consistency', 0.33530813455581665),\n",
       " ('reliability', 0.325817734003067),\n",
       " ('availability', 0.31300684809684753),\n",
       " ('compliance', 0.3017086684703827),\n",
       " ('frameits', 0.2888759672641754),\n",
       " ('lineage', 0.2830910384654999),\n",
       " ('security', 0.2805323600769043),\n",
       " ('privacy', 0.2762299180030823),\n",
       " ('followingconsumer', 0.27621662616729736)]"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "model.most_similar(\"integrity\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('spark', 0.43477481603622437),\n",
       " ('scala', 0.3810179531574249),\n",
       " ('keras', 0.3605492115020752),\n",
       " ('pandas', 0.3562259376049042),\n",
       " ('panda', 0.3393400013446808),\n",
       " ('geopandas', 0.3307809829711914),\n",
       " ('bigquery', 0.32360467314720154),\n",
       " ('pytorch', 0.32095879316329956),\n",
       " ('python', 0.3196185231208801),\n",
       " ('dask', 0.31692153215408325)]"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "model.most_similar(\"pyspark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('younglooking', 0.26352280378341675),\n",
       " ('giroux', 0.25816887617111206),\n",
       " ('muufl', 0.2439907193183899),\n",
       " ('gawande', 0.24306219816207886),\n",
       " ('valuenothing', 0.23543716967105865),\n",
       " ('adornment', 0.23438489437103271),\n",
       " ('criteriaone', 0.23263442516326904),\n",
       " ('underlaying', 0.23235675692558289),\n",
       " ('overcomplete', 0.23194748163223267),\n",
       " ('emtech', 0.2314153015613556)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.most_similar(\"king\")"
   ]
  },
  {
   "source": [
    "From a first glance, this looks okay.  \n",
    "* Integrity gives other nouns that describe the constitution of something. \n",
    "* pyspark is similar to other python libraries with closest similarities to its siblings (Spark and Scala)\n",
    "* king gives different similarities to other terms.  Seems like those esimilar terms are uplifting.  It makes sense that Queen may not show up because this corpus may not even contain that term. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We can test using the famous King - Man = Queen example. \n",
    "\n",
    "We don't get exact matches for the traditional King and Queen but it is to be expected with a small corpus.  \n",
    "*However*, if we try combinations with data science context, we get better results!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('king', 0.6999312043190002),\n",
       " ('asymptotic', 0.23131296038627625),\n",
       " ('processmachine', 0.2307613044977188),\n",
       " ('younglooking', 0.2303832322359085),\n",
       " ('saliencyguided', 0.22898586094379425),\n",
       " ('underlaying', 0.22815591096878052),\n",
       " ('aj', 0.2259904444217682),\n",
       " ('muufl', 0.22169552743434906),\n",
       " ('shao', 0.2213234305381775),\n",
       " ('softened', 0.2211374193429947)]"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "model.similar_by_vector(model['king'] - model['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('scala', 0.8702682256698608),\n",
       " ('python', 0.788196325302124),\n",
       " ('java', 0.4596204161643982),\n",
       " ('pytorch', 0.43595853447914124),\n",
       " ('julia', 0.4249792993068695),\n",
       " ('pyspark', 0.4242379665374756),\n",
       " ('plotly', 0.42139214277267456),\n",
       " ('javascript', 0.4102274775505066),\n",
       " ('sql', 0.37776073813438416),\n",
       " ('ggplot', 0.3705998659133911)]"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "model.similar_by_vector(model['python'] + model['scala'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('project', 0.7329937815666199),\n",
       " ('python', 0.7092459201812744),\n",
       " ('projects', 0.5556811690330505),\n",
       " ('pythonthe', 0.3842272460460663),\n",
       " ('tutorial', 0.35284870862960815),\n",
       " ('task', 0.35004037618637085),\n",
       " ('projectif', 0.3434600234031677),\n",
       " ('exercise', 0.34310513734817505),\n",
       " ('pytorch', 0.3402515649795532),\n",
       " ('startup', 0.33660030364990234)]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "model.similar_by_vector(model['python'] + model['project'])"
   ]
  },
  {
   "source": [
    "### To Do:\n",
    "* Go back and chck for typos in raw text.  Some words are concatenated that may not be intentional. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Doc2Vec Document Similarity\n",
    "\n",
    "*document vectors are stored in the model by index.  To look up by the document you will have to find the index associated with the article_id tag*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3406"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "# Let's look at the first document in the model\n",
    "id_1 = int(model.docvecs.index_to_doctag(0))\n",
    "id_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Iteratively Finding a Good Machine Learning Model'"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "articles.loc[id_1]['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_similar_titles(model, articles, idx, n_to_show=5):\n",
    "    \"\"\"\n",
    "    Helper Function to look up similar articles from the corpus\n",
    "    \"\"\"\n",
    "    check_id = int(model.docvecs.index_to_doctag(idx))\n",
    "    print(f\"The title of the article selected is: {articles.loc[check_id]['title']}\")\n",
    "    print(f\"It's article id is: {check_id}\\n\")\n",
    "\n",
    "    print(f\"The {n_to_show} most similar articles are:\")\n",
    "    similar_articles = model.docvecs.most_similar(idx)\n",
    "    print(\"Article ID:\\tTitle:\")\n",
    "    for j in range(n_to_show):\n",
    "        current_id = int(similar_articles[j][0])\n",
    "        print(f\"{current_id}\\t\\t{articles.loc[current_id]['title']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The title of the article selected is: The essence of eigenvalues and eigenvectors in Machine Learning\nIt's article id is: 17887\n\nThe 5 most similar articles are:\nArticle ID:\tTitle:\n57051\t\tMy take on 25 Questions to test a Data Scientist on Image Processing with Interactive Code- Part 1\n52744\t\tLocal Outlier Factor for Anomaly Detection\n62876\t\tUnderstanding how to explain predictions with “explanation vectors”\n41447\t\tnan\n40384\t\tnan\n"
     ]
    }
   ],
   "source": [
    "show_similar_titles(model, articles, 934)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The title of the article selected is: Coreference Resolution in Python\nIt's article id is: 18957\n\nThe 5 most similar articles are:\nArticle ID:\tTitle:\n54207\t\tLarge-scale Graph Mining with Spark: Part 2\n58192\t\tText Similarity with TensorFlow.js Universal Sentence Encoder\n46848\t\tNatural Language Processing: A beginner’s guide part-II\n16318\t\tA Beginner’s Guide to Rasa NLU for Intent Classification and Named-entity Recognition\n55230\t\tA Practitioner's Guide to Natural Language Processing (Part I) — Processing & Understanding Text\n"
     ]
    }
   ],
   "source": [
    "show_similar_titles(model, articles, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The title of the article selected is: How to be Good at Algorithms?\nIt's article id is: 25970\n\nThe 5 most similar articles are:\nArticle ID:\tTitle:\n57650\t\t8 Common Data Structures every Programmer must know\n44321\t\tIntroduction to 8 Essential Data Structures\n32068\t\tHow I Taught Myself Linked Lists\n18084\t\t3 Programming Concepts for Data Scientists\n46402\t\tData Structures — Simplified and Classified\n"
     ]
    }
   ],
   "source": [
    "show_similar_titles(model, articles, 3874)"
   ]
  },
  {
   "source": [
    "## Using Doc2Vec to document similarity to vector similarity\n",
    "* Convert String to W2V\n",
    "* Compare W2V to D2V"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = model.infer_vector(\"Beginnner Projects for Data Science\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('51487', 0.5366455316543579),\n",
       " ('51375', 0.533961296081543),\n",
       " ('40853', 0.5326160192489624),\n",
       " ('51431', 0.5314090251922607),\n",
       " ('51538', 0.5269762277603149),\n",
       " ('40972', 0.5228385925292969),\n",
       " ('40384', 0.5165457725524902),\n",
       " ('40662', 0.5165322422981262),\n",
       " ('41511', 0.515238881111145),\n",
       " ('41198', 0.5151280760765076)]"
      ]
     },
     "metadata": {},
     "execution_count": 121
    }
   ],
   "source": [
    "model.docvecs.most_similar([query_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_doc_by_query(query, n_to_show=5):\n",
    "    assert type(query)==str\n",
    "    query_vector = model.infer_vector(query.split())\n",
    "    similar_articles = model.docvecs.most_similar([query_vector])\n",
    "    for j in range(n_to_show):\n",
    "        current_id = int(similar_articles[j][0])\n",
    "        intro = articles.loc[current_id]['body'].replace('{','').split('\",\"')[0]\n",
    "        print(f\"Article ID:\\t{current_id}\")\n",
    "        print(f\"Title: \\t\\t{articles.loc[current_id]['title']}\")\n",
    "        print(f\"Intro: \\t\\t{intro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Article ID:\t21761\nTitle: \t\tExploring the Python Pandas Library\nIntro: \t\t\"Pandas is a python library used for analyzing, transforming, and generating statistics from data. In this post, we will discuss several useful methods in Pandas for data wrangling and exploration. For our purposes, we will be using the Medical Cost Personal Datasets data from Kaggle.\nArticle ID:\t21478\nTitle: \t\tPivoting to Efficient Data Summaries\nIntro: \t\t\"One of the most powerful tools across all professions and industry is the Pivot Table. In most traditional analytics, Microsoft Excel serves as a must-have skill and a pivot table is the core of data exploration. They are dynamic, relatively straight forward, and provide vital summaries at both surface and in-depth levels of the data.\nArticle ID:\t24847\nTitle: \t\tUsing clustering to improve classification — a use case\nIntro: \t\t\"In today’s blog, we are going to give the intuition of one of our early articles published in a Hindawi Journal named “International Scholarly Research Notices” [Refrence 1]. The plot of the story is given in the title. The genre is text classification. The main protagonists are naive-Bayes and k-means.\nArticle ID:\t61723\nTitle: \t\tFeature Selection and Dimensionality Reduction\nIntro: \t\t\"According to wikipedia, “feature selection is the process of selecting a subset of relevant features for use in model construction” or in other words, the selection of the most important features.\nArticle ID:\t44526\nTitle: \t\tGetting Started with SNAP Toolbox in Python\nIntro: \t\t\"Developed by the European Space Agency (ESA), SNAP is a common software platform that supports the Sentinel missions. It consists of several modules that can be modified and re-used for image processing, modelling and visualization of data from earth observation satellites. SNAP can be utilized not only as a research support tool for Sentinel missions (Sentinel 1, Sentinel 2 and Sentinel 3) but also as a functional outlet for effectively processing large amounts of satellite data, including data from other missions such as Landsat, MODIS and RapidEye in various different formats. The project page of SNAP and the individual toolboxes can be found at http://step.esa.int.\n"
     ]
    }
   ],
   "source": [
    "similar_doc_by_query(\"Random Forest For Classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Article ID:\t47065\nTitle: \t\tExploring Greater Sydney suburbs\nIntro: \t\t\"This was part of my IBM Data Science Professional Certificate’s capstone project. Read on and follow the link to source code and feel free to use.\nArticle ID:\t46525\nTitle: \t\tAn Introduction to Nine Essential Machine Learning Algorithms\nIntro: \t\t\"If this is the kind of stuff that you like, be one of the FIRST to subscribe to my new YouTube channel here! While there aren’t any videos yet, I’ll be sharing lots of amazing content like this but in video form. Thanks for your support :)\nArticle ID:\t34409\nTitle: \t\tThe Math Behind Deepfakes\nIntro: \t\t\"Although many are familiar with the incredible results produced by deepfakes, most people find it hard to understand how the deepfakes actually work. Hopefully, this article will demystify some of the math that goes into creating a deepfake.\nArticle ID:\t51550\nTitle: \t\tMarkov Chain Monte Carlo\nIntro: \t\t\"When I learned Markov Chain Monte Carlo (MCMC) my instructor told us there were three approaches to explaining MCMC.\nArticle ID:\t23312\nTitle: \t\tA Mathematical Explanation of Naive Bayes in 5 Minutes\nIntro: \t\t\"Naive Bayes. What may seem like a very confusing algorithm is actually one of the simplest algorithms once understood. Part of why it’s so simple to understand and implement is because of the assumptions that it inherently makes. However, that’s not to say that it’s a poor algorithm despite the strong assumptions that it holds — in fact, Naive Bayes is widely used in the data science world and has a lot of real-life applications.\n"
     ]
    }
   ],
   "source": [
    "similar_doc_by_query(\"Random Forest Tutorial\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\"Latest picks:\"}'"
      ]
     },
     "metadata": {},
     "execution_count": 157
    }
   ],
   "source": [
    "articles.loc[51375]['body'].replace('{', '').split('\",\"')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "metadata": {},
     "execution_count": 163
    }
   ],
   "source": [
    "len(articles[articles.author == 'TDS Editors']) # Need to remove TDS Editors from Corpus! ~300 documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3.701691695346365"
      ]
     },
     "metadata": {},
     "execution_count": 165
    }
   ],
   "source": [
    "model.total_train_time/3600"
   ]
  },
  {
   "source": [
    "## Topic Model with Doc2Vec\n",
    "We will try clustering with PCA(2) and then DBSCAN to check for clusters.  \n",
    "Steps:  \n",
    "1. Need a conversion from the model's document index to its associated document tags  \n",
    "2. PCA to visualize.   May need to rewrite the PCA Visualization plot to add in context of terms.  Maybe use titles of articles to do visual analysis?  \n",
    "3. Use DBSCAN to search for clusters based on density.  Not sure about distance metric yet.   "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[-0.2086484 ,  0.74766654, -0.13281198, ..., -4.418513  ,\n",
       "         3.863445  , -1.003898  ],\n",
       "       [ 0.6898131 ,  0.07900671,  0.6799487 , ..., -3.2480214 ,\n",
       "         3.2630968 ,  0.27556705],\n",
       "       [-2.7516708 ,  0.10931432,  0.22373906, ...,  0.50017786,\n",
       "        -0.6704044 , -2.082502  ],\n",
       "       ...,\n",
       "       [ 3.4422028 ,  1.0311323 , -4.259427  , ..., -2.8754826 ,\n",
       "        -0.26456988, -0.451631  ],\n",
       "       [-2.4910774 ,  1.1628321 , -2.2151136 , ..., -0.9286146 ,\n",
       "         0.50013655, -2.3644364 ],\n",
       "       [ 0.21698952, -0.774499  , -2.809891  , ...,  0.57830733,\n",
       "         0.59509945, -0.08918346]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "model.docvecs.vectors_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_features = PCA(2)"
   ]
  }
 ]
}