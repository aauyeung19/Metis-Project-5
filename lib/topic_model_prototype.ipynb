{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.5 64-bit ('spark': conda)",
      "metadata": {
        "interpreter": {
          "hash": "258ac9dacf52a9f1ab5bf3e30bc7ee43d0d8d18db3d9056252a7bd0c013d9f1d"
        }
      }
    },
    "colab": {
      "name": "topic_model_prototype.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtEiFYflCfFp"
      },
      "source": [
        "**The following cell must be run when using Google Colab to set up the notebook.**"
      ]
    },
    {
      "source": [
        "# import sys\n",
        "# sys.path.append('/content/drive/MyDrive/towards_ds_topic_modeling')\n",
        "# \n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# \n",
        "# !python -m spacy download en_core_web_md\n",
        "# !pip install pyspark"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "VxmLgCBC1FXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07423d13-265e-4b43-8f92-86a4032eb990"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XO1ZcH9ipSEV"
      },
      "source": [
        "# Topic Model Notebook\n",
        "Author: Andrew  \n",
        "\n",
        "This notebook will outline the steps used when cleaning the raw articles from Towards Data Science. \n",
        "\n",
        "Steps are adapted from \n",
        "* [PySpark for Natural Language Processing on Dataproc](https://codelabs.developers.google.com/codelabs/spark-nlp/#7)\n",
        "* [Topic Modelling with PySpark and Spark NLP by Maria Obedkova](https://medium.com/trustyou-engineering/topic-modelling-with-pyspark-and-spark-nlp-a99d063f1a6e)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PZoljv3pSEV"
      },
      "source": [
        "# Load Libraries\n",
        "import pyspark"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "GHmqiwNjpSEW",
        "outputId": "b3cb1464-3293-4eb9-cc51-4c7a3b6dd3e2"
      },
      "source": [
        "# start SparkSession\n",
        "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
        "spark.getActiveSession()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7fa750e7bcd0>"
            ],
            "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://andrews-mbp.fios-router.home:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jr89q93pSEX"
      },
      "source": [
        "# load CSV\n",
        "# use the following when running on Colab\n",
        "articles = spark.read.csv('../src/TDS_articles.csv', inferSchema=True, header=True, sep=\"\\t\")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjSY-fQ0pSEX",
        "outputId": "feb7aff4-93bb-41de-fc2b-88b65da748db"
      },
      "source": [
        "articles.show()"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\n|article_id|               title|            subtitle|             author|      date|claps|images|codeblocks|                link|                body|\n+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\n|      3406|Iteratively Findi...|             Gear Up|       Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"{\"\"There is a th...|\n|      5405|Why Get a Data Ex...|                null|       Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      5957|The curse of know...|                null|          Iwo Herka|2019-11-26| null|     0|         0|https://towardsda...|\"{\"\"Why are compe...|\n|      6932|Image segmentatio...|                null|       Jakub Czakon|      null| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      8041|Introducing Model...|The Model Fitting...|        Peter Grant|2019-07-20| null|     0|         0|https://towardsda...|\"{\"\"In a previous...|\n|      8060|How to Quickly Co...|How to get a quic...|     Costas Andreou|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Every now and...|\n|      8061|How to query and ...|A Standard SQL co...|Johan van de Werken|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"When I first ...|\n|      8062|How to Create an ...|Get It Done in 5 ...|       Low Wei Hong|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Are you bored...|\n|      8063|Breaking Down the...|                null|       Temple Moore|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"As a budding ...|\n|      8064|What TV show has ...|Breaking Bad or G...|     Mubarak Ganiyu|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"“Next episode...|\n|      8065|Detecting station...| Looking at the data|       Shay Palachy|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Stationarity ...|\n|      8066|Analysis of Bosto...|                null|       Hannah Huang|2019-07-20| null|     0|         0|https://towardsda...|\"{\"\"While I was l...|\n|      8068|Deep Learning on ...|Predict multiple ...|      Nikita sharma|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"A multi-label...|\n|      8069|9 Tips For Traini...|                null|     William Falcon|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Let’s face it...|\n|      8070|A Gentle Introduc...|                Path|       Xavier Sumba|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Recently, gra...|\n|      8071|Facebook vs. EU A...|The new FRA paper...|  Alex Moltzau 莫战|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      8072|Can Neural Networ...|Building an NLP M...|       Sameer Ahuja|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Deciphering F...|\n|      8073|The 5 Sampling Al...|       DS Algorithms|      Rahul Agarwal|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Data Science ...|\n|      8074|The Inception of ...|                null|      Shailja Gupta|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"In the match ...|\n|      8075|Panoptic Segmenta...|Combining Semanti...|    Vaishak V.Kumar|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"A new task ca...|\n+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd1B9MJXpSEX"
      },
      "source": [
        "## Checkout Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRH5AtCxpSEX"
      },
      "source": [
        "# register SQL table\n",
        "articles.registerTempTable('articles')"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Sfx6qk_pSEX",
        "outputId": "ffca42aa-9dcf-43ac-bbe3-11128e248e66"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT * FROM articles;\n",
        "\"\"\"\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\n|article_id|               title|            subtitle|             author|      date|claps|images|codeblocks|                link|                body|\n+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\n|      3406|Iteratively Findi...|             Gear Up|       Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"{\"\"There is a th...|\n|      5405|Why Get a Data Ex...|                null|       Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      5957|The curse of know...|                null|          Iwo Herka|2019-11-26| null|     0|         0|https://towardsda...|\"{\"\"Why are compe...|\n|      6932|Image segmentatio...|                null|       Jakub Czakon|      null| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      8041|Introducing Model...|The Model Fitting...|        Peter Grant|2019-07-20| null|     0|         0|https://towardsda...|\"{\"\"In a previous...|\n|      8060|How to Quickly Co...|How to get a quic...|     Costas Andreou|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Every now and...|\n|      8061|How to query and ...|A Standard SQL co...|Johan van de Werken|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"When I first ...|\n|      8062|How to Create an ...|Get It Done in 5 ...|       Low Wei Hong|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Are you bored...|\n|      8063|Breaking Down the...|                null|       Temple Moore|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"As a budding ...|\n|      8064|What TV show has ...|Breaking Bad or G...|     Mubarak Ganiyu|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"“Next episode...|\n|      8065|Detecting station...| Looking at the data|       Shay Palachy|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Stationarity ...|\n|      8066|Analysis of Bosto...|                null|       Hannah Huang|2019-07-20| null|     0|         0|https://towardsda...|\"{\"\"While I was l...|\n|      8068|Deep Learning on ...|Predict multiple ...|      Nikita sharma|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"A multi-label...|\n|      8069|9 Tips For Traini...|                null|     William Falcon|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Let’s face it...|\n|      8070|A Gentle Introduc...|                Path|       Xavier Sumba|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Recently, gra...|\n|      8071|Facebook vs. EU A...|The new FRA paper...|  Alex Moltzau 莫战|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"This article ...|\n|      8072|Can Neural Networ...|Building an NLP M...|       Sameer Ahuja|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Deciphering F...|\n|      8073|The 5 Sampling Al...|       DS Algorithms|      Rahul Agarwal|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"Data Science ...|\n|      8074|The Inception of ...|                null|      Shailja Gupta|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"In the match ...|\n|      8075|Panoptic Segmenta...|Combining Semanti...|    Vaishak V.Kumar|2019-07-21| null|     0|         0|https://towardsda...|\"{\"\"A new task ca...|\n+----------+--------------------+--------------------+-------------------+----------+-----+------+----------+--------------------+--------------------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA87WbZPpSEX",
        "outputId": "6634c7b2-b488-4760-d32d-f20b66edd8ac"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT COUNT(subtitle)\n",
        "FROM articles\n",
        "WHERE subtitle like CONCAT('%', author, '%');\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+\n|count(subtitle)|\n+---------------+\n|             75|\n+---------------+\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bUagzSapSEX"
      },
      "source": [
        "Some of the Authors are replicated in the subtitles. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oC8BRiTpSEX",
        "outputId": "6d936218-265a-46ca-8081-428fe6e351bb"
      },
      "source": [
        "query = \"\"\"\n",
        "SELECT COUNT(title), COUNT(body)\n",
        "FROM articles;\n",
        "\"\"\"\n",
        "\n",
        "spark.sql(query).show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+\n|count(title)|count(body)|\n+------------+-----------+\n|       35507|      35646|\n+------------+-----------+\n\n"
          ]
        }
      ]
    },
    {
      "source": [
        "Of the entire corpus, only about 100 articles do not have a Title associated with them"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkUByQxDGaVZ"
      },
      "source": [
        "## Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udkl3a-zpSEX"
      },
      "source": [
        "# Register cleaning function as UDF \n",
        "from cleaning import clean_doc\n",
        "from pyspark.sql.functions import udf, split, explode, col, posexplode\n",
        "from pyspark.sql.types import *"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UCbQOCq0Mq5"
      },
      "source": [
        "# add the cleaning function as a UDF\n",
        "clean_udf = udf(clean_doc)\n",
        "\n",
        "# make a UDF to remove the bracket delimiters\n",
        "remove_brackets = udf(lambda row: row.replace('}\"', '').replace('\"{\"', ''))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9m3S2PtDuXb",
        "outputId": "d3accc8f-0e73-4712-9ee8-63032545d0a1"
      },
      "source": [
        "# apply remove brackets to body column\n",
        "articles = (articles\n",
        "  .withColumn('body', remove_brackets('body'))\n",
        "  )\n",
        "\n",
        "articles.show(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------------------+------------+----------+-----+------+----------+--------------------+--------------------+\n|article_id|               title|            subtitle|      author|      date|claps|images|codeblocks|                link|                body|\n+----------+--------------------+--------------------+------------+----------+-----+------+----------+--------------------+--------------------+\n|      3406|Iteratively Findi...|             Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|\n|      5405|Why Get a Data Ex...|                null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|\n|      5957|The curse of know...|                null|   Iwo Herka|2019-11-26| null|     0|         0|https://towardsda...|\"Why are competen...|\n|      6932|Image segmentatio...|                null|Jakub Czakon|      null| null|     0|         0|https://towardsda...|\"This article was...|\n|      8041|Introducing Model...|The Model Fitting...| Peter Grant|2019-07-20| null|     0|         0|https://towardsda...|\"In a previous ar...|\n+----------+--------------------+--------------------+------------+----------+-----+------+----------+--------------------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImQABjxcBBba"
      },
      "source": [
        "Use *posexplode* to separate the body of the article into its paragraphs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1a6MuSe0hFY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f7a421-57b4-441b-970b-9cd826899c79"
      },
      "source": [
        "articles_by_paragraph = (articles\n",
        "  .select('*', posexplode(split(col('body'), '\",\"')))\n",
        "  .withColumnRenamed('pos', 'p_index')\n",
        "  .withColumnRenamed('col', 'paragraph')\n",
        "  )\n",
        "\n",
        "articles_by_paragraph.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+--------+------------+----------+-----+------+----------+--------------------+--------------------+-------+--------------------+\n|article_id|               title|subtitle|      author|      date|claps|images|codeblocks|                link|                body|p_index|           paragraph|\n+----------+--------------------+--------+------------+----------+-----+------+----------+--------------------+--------------------+-------+--------------------+\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      0|\"There is a theor...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      1|\"You may have hea...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      2|\"There is no free...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      3|\"Given all these,...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      4|\"Agile methodolog...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      5|\"In first iterati...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      6|\"An instance of a...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      7|\"After your first...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      8|\"You always deriv...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|      9|\"For instance if ...|\n|      3406|Iteratively Findi...| Gear Up|Kemal Tugrul|2018-03-24| null|     0|         0|https://towardsda...|\"There is a theor...|     10|\"* One can argue ...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      0|\"This article is ...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      1|\"I found an artic...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      2|\"Architect and Bu...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      3|\"Communicate with...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      4|\"Lead all aspects...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      5|\"Develop producti...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      6|\"To those in the ...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      7|\"Responsibilities...|\n|      5405|Why Get a Data Ex...|    null|Lester Leong|2019-07-02| null|     0|         0|https://towardsda...|\"This article is ...|      8|\"Of course, it wo...|\n+----------+--------------------+--------+------------+----------+-----+------+----------+--------------------+--------------------+-------+--------------------+\nonly showing top 20 rows\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIjPq8b7pSEX"
      },
      "source": [
        "# Clean \"body\" with udf\n",
        "clean_df = articles.withColumn(\"clean_body\", clean_udf(\"body\"))\n",
        "\n",
        "clean_df.show(5)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQS5wM5mpSEY",
        "outputId": "8b311087-2367-42ba-a1e6-feb9d7ce0f9b"
      },
      "source": [
        "clean_df.printSchema()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n |-- article_id: integer (nullable = true)\n |-- title: string (nullable = true)\n |-- subtitle: string (nullable = true)\n |-- author: string (nullable = true)\n |-- date: string (nullable = true)\n |-- claps: integer (nullable = true)\n |-- images: integer (nullable = true)\n |-- codeblocks: integer (nullable = true)\n |-- link: string (nullable = true)\n |-- body: string (nullable = true)\n |-- clean_body: string (nullable = true)\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFI91g_fpSEY"
      },
      "source": [
        "## Making the Pipeline for Title Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mToecbixpSEY"
      },
      "source": [
        "# import from pyspark machine learning\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import CountVectorizer, StopWordsRemover, IDF\n",
        "from pyspark.ml.clustering import LDA"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "source": [
        "**For the following, the pipeline will be written to perform topic modeling on the Titles of the articles.**\n",
        "For use with other documents, the training data should label the feature column as \"text\"."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+\n|article_id|                text|\n+----------+--------------------+\n|      3406|[iteratively, fin...|\n|      5405|   [data, executive]|\n|      5957|  [curse, knowledge]|\n|      6932|[image, segmentat...|\n|      8041|[introduce, model...|\n+----------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "train = (\n",
        "    articles\n",
        "        .select('article_id', 'title')\n",
        "        .where(col('title').isNotNull())\n",
        "        .withColumn('title', clean_udf('title'))\n",
        "        .withColumn('title', split(col('title'), ' '))\n",
        "        .withColumnRenamed('title', 'text')\n",
        "    )\n",
        "train.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf = CountVectorizer(inputCol='text', outputCol='tf_result')\n",
        "idf = IDF(inputCol=tf.getOutputCol(), outputCol='features')\n",
        "lda = LDA(k=20, maxIter=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = Pipeline(stages=[tf, idf, lda])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = pipe.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = model.stages[0].vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "topics = model.stages[2].describeTopics().collect()\n",
        "topic_idx = [topic.termIndices for topic in topics]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[80, 123, 136, 203, 158, 244, 291, 19, 222, 295],\n",
              " [13, 35, 34, 36, 7, 177, 90, 75, 155, 255],\n",
              " [23, 37, 33, 88, 1, 4, 225, 27, 171, 0],\n",
              " [15, 0, 32, 47, 5, 50, 19, 6, 3, 127],\n",
              " [98, 160, 254, 264, 139, 303, 234, 288, 511, 333],\n",
              " [46, 81, 3, 10, 196, 0, 111, 181, 2, 5],\n",
              " [41, 202, 199, 271, 74, 275, 404, 381, 324, 601],\n",
              " [28, 60, 39, 25, 265, 286, 262, 502, 294, 142],\n",
              " [45, 138, 261, 251, 115, 410, 423, 230, 484, 458],\n",
              " [17, 11, 72, 192, 270, 42, 7, 103, 267, 220],\n",
              " [49, 5, 0, 147, 188, 169, 56, 191, 73, 246],\n",
              " [1, 8, 14, 4, 9, 2, 21, 11, 18, 20],\n",
              " [141, 9, 257, 2, 18, 70, 108, 369, 470, 290],\n",
              " [99, 53, 2, 146, 30, 350, 280, 308, 29, 250],\n",
              " [10, 58, 38, 105, 327, 273, 263, 302, 85, 399],\n",
              " [5, 0, 63, 124, 129, 205, 150, 7, 305, 106],\n",
              " [83, 148, 227, 180, 396, 446, 281, 625, 361, 393],\n",
              " [79, 112, 92, 190, 100, 237, 64, 226, 219, 110],\n",
              " [133, 221, 228, 157, 332, 434, 102, 343, 362, 3],\n",
              " [162, 3, 208, 97, 151, 479, 380, 995, 301, 565]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "topic_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_topics(vocab, topic_indexes, topic_labels=None):\n",
        "    if not topic_labels:\n",
        "        topic_labels = [\"Topic \" + str(i) for i in range(len(topic_indexes))]\n",
        "    assert len(topic_labels) == len(topic_indexes)\n",
        "\n",
        "    for label, words in zip(topic_labels, topic_indexes):\n",
        "        topic_words = ', '.join([vocab[word_idx] for word_idx in words])\n",
        "        print(label + ': ' + topic_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: cloud, gradient, mean, automate, logistic, descent, predictive, regression, theory, platform\nTopic 1: learn, artificial, intelligence, google, ai, scikit, review, business, kaggle, state\nTopic 2: r, visualization, understand, graph, learning, machine, database, predict, detect, data\nTopic 3: scientist, data, know, linear, science, need, regression, datum, python, engineering\nTopic 4: spark, apache, pyspark, knowledge, pipeline, chart, forest, management, charts, hand\nTopic 5: start, approach, python, analysis, probability, data, twitter, exploratory, use, science\nTopic 6: step, complete, recommender, different, system, gpu, miss, steps, github, football\nTopic 7: detection, object, vs, code, type, matrix, vector, global, anomaly, cnn\nTopic 8: covid, game, company, environment, example, tech, trends, development, brief, virtual\nTopic 9: networks, neural, base, docker, bayes, nlp, ai, line, topic, coronavirus\nTopic 10: new, science, data, solve, right, best, way, technique, problem, matplotlib\nTopic 11: learning, deep, build, machine, model, use, time, neural, classification, introduction\nTopic 12: multi, model, class, use, classification, good, find, stop, imbalanced, flask\nTopic 13: power, web, use, scrape, create, chatbot, bi, important, pandas, teach\nTopic 14: analysis, explain, text, analyze, style, mining, impact, overview, sentiment, generation\nTopic 15: science, data, big, stock, future, journey, market, ai, great, analytic\nTopic 16: decision, tree, understanding, life, demystify, digital, architecture, perform, accuracy, solution\nTopic 17: computer, vision, analytics, face, k, building, aws, plotly, d, clustering\nTopic 18: optimization, forecast, year, generate, loss, component, function, information, basics, python\nTopic 19: map, python, story, app, statistic, avoid, sheet, hotel, ways, tips\n"
          ]
        }
      ],
      "source": [
        "show_topics(vocab, topic_idx)"
      ]
    },
    {
      "source": [
        "## Making the Pipeline for Article Topic Modeling"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------+--------------------+\n|article_id|p_index|                text|\n+----------+-------+--------------------+\n|      3406|      0|[theorem, tell, s...|\n|      3406|      1|[hear, free, lunc...|\n|      3406|      2|[free, lunch, met...|\n|      3406|      3|[good, idea, expl...|\n|      3406|      4|[agile, methodolo...|\n+----------+-------+--------------------+\nonly showing top 5 rows\n\n"
          ]
        }
      ],
      "source": [
        "para_train = (\n",
        "    articles_by_paragraph\n",
        "        .select('article_id', 'p_index', 'paragraph') # select unique identifiers\n",
        "        .where(col('paragraph').isNotNull()) # ignore blank paragraphs\n",
        "        .withColumn('paragraph', clean_udf('paragraph')) # clean the text\n",
        "        .withColumn('paragraph', split(col('paragraph'), ' ')) # split on blank space to tokenize words\n",
        "        .withColumnRenamed('paragraph', 'text') # rename column to text for pipeline\n",
        "    )\n",
        "para_train.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf = CountVectorizer(inputCol='text', outputCol='tf_result', minDF=0.05, maxDF=0.6)\n",
        "idf = IDF(inputCol=tf.getOutputCol(), outputCol='features')\n",
        "lda = LDA(k=20, maxIter=10)\n",
        "paragraph_pipe = Pipeline(stages=[tf, idf, lda])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "para_model = paragraph_pipe.fit(para_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "para_model.save(\"../models/articles_LDA\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Param(parent='CountVectorizer_dd7b58202f7d', name='vocabSize', doc='max size of the vocabulary. Default 1 << 18.')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "para_model.stages[0].vocabSize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab2 = para_model.stages[0].vocabulary\n",
        "topics2 = para_model.stages[2].describeTopics().collect()\n",
        "topic_idx2 = [topic.termIndices for topic in topics2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: create, way, let, data, datum, use, learning, look, like, value\nTopic 1: use, work, example, way, need, function, datum, like, model, s\nTopic 2: set, example, use, create, let, look, datum, time, data, function\nTopic 3: value, work, use, time, data, way, like, example, need, datum\nTopic 4: model, example, way, use, s, datum, learning, set, good, let\nTopic 5: like, want, use, create, find, datum, code, good, learn, time\nTopic 6: function, use, create, set, datum, s, like, model, need, code\nTopic 7: learn, use, learning, way, data, model, function, datum, set, want\nTopic 8: way, need, find, work, datum, data, use, code, value, set\nTopic 9: need, want, set, value, model, use, like, create, datum, function\nTopic 10: code, let, use, need, function, work, find, time, look, data\nTopic 11: good, example, use, datum, work, model, need, learn, learning, like\nTopic 12: look, like, model, use, let, way, learning, want, example, datum\nTopic 13: learning, work, data, datum, set, like, want, use, learn, way\nTopic 14: s, use, like, datum, find, work, create, way, model, need\nTopic 15: time, datum, use, model, need, example, like, want, s, learn\nTopic 16: datum, data, model, use, way, s, learning, work, need, want\nTopic 17: find, value, datum, set, use, good, way, want, data, let\nTopic 18: learning, let, use, s, value, model, example, datum, code, create\nTopic 19: data, datum, use, time, set, model, good, create, work, need\n"
          ]
        }
      ],
      "source": [
        "show_topics(vocab2, topic_idx2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}