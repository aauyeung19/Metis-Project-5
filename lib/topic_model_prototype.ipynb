{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('spark': conda)",
   "metadata": {
    "interpreter": {
     "hash": "258ac9dacf52a9f1ab5bf3e30bc7ee43d0d8d18db3d9056252a7bd0c013d9f1d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Topic Model Notebook\n",
    "Author: Andrew  \n",
    "\n",
    "This notebook will outline the steps used when cleaning the raw articles from Towards Data Science. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8e4740d490>"
      ],
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://andrews-mbp.fios-router.home:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# start SparkSession\n",
    "spark = pyspark.sql.SparkSession.builder.config(\"spark.driver.memory\", \"15g\").getOrCreate()\n",
    "spark.getActiveSession()"
   ]
  },
  {
   "source": [
    "## Clean Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV into Spark\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../src/TDS_articles.csv', index_col=0)\n",
    "\n",
    "mySchema = StructType([ StructField(\"title\", StringType(), True)\\\n",
    "                       ,StructField(\"subtitle\", StringType(), True)\\\n",
    "                       ,StructField(\"author\", StringType(), True)\\\n",
    "                       ,StructField(\"date\", StringType(), True)\\\n",
    "                       ,StructField(\"body\", StringType(), True)\\\n",
    "                       ,StructField(\"link\", StringType(), True)\\\n",
    "                       ,StructField(\"article_id\", IntegerType(), True)])\n",
    "\n",
    "articles = spark.createDataFrame(df, schema=mySchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the pandas df to save memory\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\n|               title|            subtitle|              author|      date|                body|                link|article_id|\n+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\n|Lessons Learned F...| Be prepared to code|     John Wittenauer|2014-11-25|This content orig...|https://towardsda...|         1|\n|   The Next Big Wave|                 NaN|       Salman Naseer|2017-03-03|IoT, Big Data, M2...|https://towardsda...|      1580|\n|Thinking about Da...|What might DSaaP ...|       Chris Dowsett|2016-05-29|The “usability of...|https://towardsda...|      1657|\n|The Science / Eng...|                 NaN|          Jenny Kwan|2015-07-13|As I wrote about ...|https://towardsda...|      1710|\n|So You Want to be...|                 NaN|          Jenny Kwan|2015-07-13|We could discuss ...|https://towardsda...|      1711|\n|Data representati...|                 NaN|         Andre Revin|2015-07-12|How to effectivel...|https://towardsda...|      1712|\n|Enchanted Random ...|by Jose Marcial P...|Jose Marcial Port...|2015-07-09|If you enjoy this...|https://towardsda...|      1713|\n|A little prior kn...|                 NaN|        Helen V Cook|2015-11-03|I’ve been in Scot...|https://towardsda...|      1714|\n|Ideas are bulletp...|                 NaN|         Arnav Gupta|2015-10-28|Let me begin with...|https://towardsda...|      1715|\n|                 NaN|                 NaN|        Alan Marazzi|2016-03-09|If you’re not liv...|https://towardsda...|      1716|\n|Bang for your (co...|                 NaN|    Yorgos Askalidis|2016-03-09|On December 23rd,...|https://towardsda...|      1717|\n|When to use a mac...|When is the right...|     Nikhil Dandekar|2016-03-08|Traditional Infor...|https://towardsda...|      1718|\n|Predicting Popula...|                 NaN|     Rudolph Broomes|2016-03-07|Why should anyone...|https://towardsda...|      1719|\n|A Flask API for s...|                 NaN|           Amir Ziai|2016-03-07|Scikit-learn is a...|https://towardsda...|      1720|\n|Analytics — The I...|History of Analytics|    Eugene Leychenko|2016-03-04|What if there was...|https://towardsda...|      1721|\n|Are Machines Bias...|A data scientist’...|      Alex P. Miller|2016-05-24|ProPublica recent...|https://towardsda...|      1722|\n|Programming Liter...|Taking it a littl...|       Pablo de Haro|2016-05-15|Not so long ago, ...|https://towardsda...|      1723|\n|How Data Science ...|                 NaN|         Anna Anisin|2016-06-07|Data science is r...|https://towardsda...|      1724|\n|MACHINE LEARNING ...|                 NaN|       Bruce Robbins|2016-06-07|Machine learning ...|https://towardsda...|      1725|\n|Sounds Simple Eno...|                 NaN|           Christina|2016-06-01|Real Time. Data-D...|https://towardsda...|      1726|\n+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "articles.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register SQL table\n",
    "articles.registerTempTable('articles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\n|               title|            subtitle|              author|      date|                body|                link|article_id|\n+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\n|Lessons Learned F...| Be prepared to code|     John Wittenauer|2014-11-25|This content orig...|https://towardsda...|         1|\n|   The Next Big Wave|                 NaN|       Salman Naseer|2017-03-03|IoT, Big Data, M2...|https://towardsda...|      1580|\n|Thinking about Da...|What might DSaaP ...|       Chris Dowsett|2016-05-29|The “usability of...|https://towardsda...|      1657|\n|The Science / Eng...|                 NaN|          Jenny Kwan|2015-07-13|As I wrote about ...|https://towardsda...|      1710|\n|So You Want to be...|                 NaN|          Jenny Kwan|2015-07-13|We could discuss ...|https://towardsda...|      1711|\n|Data representati...|                 NaN|         Andre Revin|2015-07-12|How to effectivel...|https://towardsda...|      1712|\n|Enchanted Random ...|by Jose Marcial P...|Jose Marcial Port...|2015-07-09|If you enjoy this...|https://towardsda...|      1713|\n|A little prior kn...|                 NaN|        Helen V Cook|2015-11-03|I’ve been in Scot...|https://towardsda...|      1714|\n|Ideas are bulletp...|                 NaN|         Arnav Gupta|2015-10-28|Let me begin with...|https://towardsda...|      1715|\n|                 NaN|                 NaN|        Alan Marazzi|2016-03-09|If you’re not liv...|https://towardsda...|      1716|\n|Bang for your (co...|                 NaN|    Yorgos Askalidis|2016-03-09|On December 23rd,...|https://towardsda...|      1717|\n|When to use a mac...|When is the right...|     Nikhil Dandekar|2016-03-08|Traditional Infor...|https://towardsda...|      1718|\n|Predicting Popula...|                 NaN|     Rudolph Broomes|2016-03-07|Why should anyone...|https://towardsda...|      1719|\n|A Flask API for s...|                 NaN|           Amir Ziai|2016-03-07|Scikit-learn is a...|https://towardsda...|      1720|\n|Analytics — The I...|History of Analytics|    Eugene Leychenko|2016-03-04|What if there was...|https://towardsda...|      1721|\n|Are Machines Bias...|A data scientist’...|      Alex P. Miller|2016-05-24|ProPublica recent...|https://towardsda...|      1722|\n|Programming Liter...|Taking it a littl...|       Pablo de Haro|2016-05-15|Not so long ago, ...|https://towardsda...|      1723|\n|How Data Science ...|                 NaN|         Anna Anisin|2016-06-07|Data science is r...|https://towardsda...|      1724|\n|MACHINE LEARNING ...|                 NaN|       Bruce Robbins|2016-06-07|Machine learning ...|https://towardsda...|      1725|\n|Sounds Simple Eno...|                 NaN|           Christina|2016-06-01|Real Time. Data-D...|https://towardsda...|      1726|\n+--------------------+--------------------+--------------------+----------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT * FROM articles;\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+---------------+\n|count(subtitle)|\n+---------------+\n|             85|\n+---------------+\n\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT COUNT(subtitle)\n",
    "FROM articles\n",
    "WHERE subtitle like CONCAT('%', author, '%');\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "source": [
    "Some of the Authors are replicated in the subtitles. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+\n|            subtitle|              author|\n+--------------------+--------------------+\n|by Jose Marcial P...|Jose Marcial Port...|\n|ashispapu (Ashis ...|         Ashis Samal|\n|By Eli Bildner, E...|         Eli Bildner|\n|Using Machine Lea...|          DeviceHive|\n|RecSys Week 1: Th...|                   R|\n|WHAT DO WE DO TO ...|                   T|\n|Sukant Khurana (@...|      Sukant Khurana|\n|Sukant Khurana (@...|      Sukant Khurana|\n|                 NaN|                 NaN|\n|                 NaN|                 NaN|\n|Co-Authors: Konst...|  Konstantinos Bozas|\n|                 NaN|                 NaN|\n|Naveen Manwani - ...|      Naveen Manwani|\n|By Zina Akrout, S...|     Samantha Bansil|\n|Applying François...|                   A|\n|You will soon be ...|                   Y|\n|Laurent El Ghaoui...|   Laurent El Ghaoui|\n|By Werlindo Mangr...|          Mia Iseman|\n|Written by Vivian...| Viviane Lindenbergh|\n|Rocket (Data) Sci...|         Yoav Tepper|\n+--------------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT subtitle, author\n",
    "FROM articles\n",
    "WHERE subtitle like CONCAT('%', author, '%');\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register cleaning function as UDF \n",
    "from cleaning import clean_doc\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "clean_udf = udf(lambda doc: clean_doc(doc), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean \"body\" with udf\n",
    "clean_df = articles.withColumn(\"clean_body\", clean_udf(\"body\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+--------------------+---------------+----------+--------------------+--------------------+----------+--------------------+\n|               title|            subtitle|         author|      date|                body|                link|article_id|          clean_body|\n+--------------------+--------------------+---------------+----------+--------------------+--------------------+----------+--------------------+\n|Lessons Learned F...| Be prepared to code|John Wittenauer|2014-11-25|This content orig...|https://towardsda...|         1|content originall...|\n|   The Next Big Wave|                 NaN|  Salman Naseer|2017-03-03|IoT, Big Data, M2...|https://towardsda...|      1580|iot big data m m ...|\n|Thinking about Da...|What might DSaaP ...|  Chris Dowsett|2016-05-29|The “usability of...|https://towardsda...|      1657|usability datum a...|\n|The Science / Eng...|                 NaN|     Jenny Kwan|2015-07-13|As I wrote about ...|https://towardsda...|      1710|write previously ...|\n|So You Want to be...|                 NaN|     Jenny Kwan|2015-07-13|We could discuss ...|https://towardsda...|      1711|discuss suspect r...|\n+--------------------+--------------------+---------------+----------+--------------------+--------------------+----------+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "clean_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- title: string (nullable = true)\n |-- subtitle: string (nullable = true)\n |-- author: string (nullable = true)\n |-- date: string (nullable = true)\n |-- body: string (nullable = true)\n |-- link: string (nullable = true)\n |-- article_id: integer (nullable = true)\n |-- clean_body: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "clean_df.printSchema()"
   ]
  },
  {
   "source": [
    "## Preprocessing - Get Document Term Matrix (dtm) "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "from pyspark.ml.clustering import LDA\n",
    "\n",
    "\n",
    "tk = Tokenizer(inputCol='clean_body', outputCol='tokens')\n",
    "vectorizer = CountVectorizer(inputCol=tk.getOutputCol(), outputCol='term_freq', minDF=0.1, )\n",
    "lda_model = LDA()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(stages=[tk, vectorizer, lda_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = tk.transform(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+\n|              tokens|\n+--------------------+\n|[content, origina...|\n|[iot, big, data, ...|\n|[usability, datum...|\n|[write, previousl...|\n|[discuss, suspect...|\n+--------------------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "clean_df.select('tokens').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do NOT Run this Cell until you talk to a TA! takes a LOT of memory\n",
    "cv = vectorizer.fit(clean_df)\n",
    "dtm = cv.transform(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}