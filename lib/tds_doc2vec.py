# -*- coding: utf-8 -*-
"""tds_doc2vec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FIhfQDaQ03qXFSdbJZRvwHw0vkSNhTSo

# Towards Data Science Doc2Vec Notebook
Author: Andrew Auyeung \

Articles from Towards Data Science can be clustered into their respective topics but generally have latent features that connect them.  This notebook will attempt to use Gensim Doc2Vec to train a model to capture those hidden connections.
"""
# Load CSV and Isolate ID and cleaned text
# Note that the text does not remove stopwords
import pandas as pd

corpus = pd.read_csv('../src/clean_text.csv', sep='\t', index_col=0)
corpus = corpus[['article_id', 'text']]
corpus.set_index('article_id', inplace=True)
corpus['text'] = corpus['text'].map(str)

# Import libraries from Gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

# tag document
tagged_corpus = [TaggedDocument(words=row[1][0].split(), tags=[str(row[0])]) for row in corpus.iterrows()]

import multiprocessing
cores = multiprocessing.cpu_count()
print(f"number of cores used: {cores}")

max_epochs = 40 # Number of epochs to train
vec_size = 100 #
alpha = 0.025 # Initial Learning Rate

model = Doc2Vec(
    dm=1,
    vector_size=vec_size,
    alpha=alpha,
    window=5,
    min_count=2,
    min_alpha=0.00025,
    workers=cores,
    negative=5,
    epochs=40
)
print('Building Vocab')
model.build_vocab(tagged_corpus)
print('Training Model')
model.train(documents=tagged_corpus, total_examples=model.corpus_count, epochs=model.epochs)
"""for epoch in range(max_epochs):
    print(f"Iteration {epoch}")
    model.train(
        documents=tagged_corpus,
        total_examples=model.corpus_count,
        epochs=model.epochs 
    )
    model.alpha -= 0.0002
    model.min_alpha = model.alpha """

model.save("../models/d2v_v5.model")
print("Model Saved")

