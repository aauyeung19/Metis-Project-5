# -*- coding: utf-8 -*-
"""tds_doc2vec.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FIhfQDaQ03qXFSdbJZRvwHw0vkSNhTSo

# Towards Data Science Doc2Vec Notebook
Author: Andrew Auyeung \

Articles from Towards Data Science can be clustered into their respective topics but generally have latent features that connect them.  This notebook will attempt to use Gensim Doc2Vec to train a model to capture those hidden connections.
"""
# Load CSV and Isolate ID and cleaned text
# Note that the text does not remove stopwords
import pandas as pd

corpus = pd.read_csv('../src/TDS_document_topic_matrix.csv', sep='\t', index_col=0)
corpus = corpus[['article_id', 'text']]
corpus.set_index('article_id', inplace=True)
corpus['text'] = corpus['text'].map(str)
corpus.head()

# Import libraries from Gensim
from gensim.models.doc2vec import Doc2Vec, TaggedDocument

# tag document
tagged_corpus = [TaggedDocument(words=row[1][0].split(), tags=str(row[0])) for row in corpus.iterrows()]

import multiprocessing
cores = multiprocessing.cpu_count()
print(cores)

max_epochs = 100 # Number of epochs to train
vec_size = 200 #
alpha = 0.025 # Initial Learning Rate

model = Doc2Vec(
    dm=1,
    vector_size=vec_size,
    alpha=alpha,
    window=5,
    min_count=2,
    min_alpha=0.00025,
    workers=cores
)

model.build_vocab(tagged_corpus)

for epoch in range(max_epochs):
    print(f"Iteration {epoch}")
    model.train(
        documents=tagged_corpus,
        total_examples=model.corpus_count,
        epochs=model.epochs
    )
    model.alpha -= 0.0002
    model.min_alpha = model.alpha

model.save("../models/d2v.model")
print("Model Saved")

